{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal\n",
    "\n",
    "## Authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Austin Flippo: Research Question, Hypothesis, Ethics\n",
    "- David Li: Research Question, Hypothesis, Data\n",
    "- Farzad Kashani: Rearch Question, Hypothesis, Background and Prior Work\n",
    "- Roxy Behjat: Research Question, Hypothesis, Background and Prior Work, Team Expectations\n",
    "- Ryan Namdar: Research Question, Hypothesis, Timeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question\n",
    "\n",
    "For Spotify songs, which audio features (such as danceability, energy, valence, tempo, loudness, acousticness, and speechiness) are most strongly associated with a song’s relative popularity within its genre? Popularity will be measured using Spotify’s track popularity score compared within genres as a percentage, and we will also include control variables such as artist popularity. We will use regression and analysis to find and understand these associations, which allows us to identify which musical features are most predictive of high relative popularity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our group began our work with the premise that what makes a hit song has become increasingly quantifiable in the era of big data and streaming platforms such as Spotify. Research into what makes a song popular, or at least what increases its likelihood of becoming a hit, has expanded rapidly in recent years. With the proliferation of music datasets and streaming platforms such as Spotify and Apple Music, researchers have sought to determine whether measurable audio features and musical characteristics are associated with commercial success, listener engagement, and critical reception. We focus on Spotify because it provides both a standardized set of audio features (danceability, energy, and valence) and a track-level popularity score on a 0-100 scale, calculated algorithmically and primarily driven by total plays and their recency.\n",
    "\n",
    "One research project by Araujo et al. <sup><a href=\"#ref1\">1</a></sup> used Spotify charts and audio features to model song popularity and predict whether a track would appear in Spotify’s Top 50 Global rankings in the future. They framed the task as a classification problem. They found that machine-learning models achieved strong predictive performance, with AUC (Area Under the Curve) values exceeding 0.80 when forecasting popularity up to two months in advance. Interestingly, they found that adding acoustic features to chart-based predictions yielded only minimal performance gains, suggesting that audio characteristics alone may have limited predictive power. This finding highlights a significant limitation and motivates our focus on identifying which specific Spotify audio features meaningfully contribute to popularity prediction rather than assuming all features are equally informative.\n",
    "\n",
    "Another related study by Ceulemans and Detry <sup><a href=\"#ref2\">2</a></sup>investigated whether musical characteristics influence commercial success and critics’ rankings preferences using a dataset of 514 songs from 2009 that appeared on multiple year-end charts. The authors constructed variables for tempo, duration, and other musical attributes. They then used regression models to assess their association with success metrics such as Billboard rank, chart longevity, and critics’ lists. Their results suggested that while some features were associated with chart survival and critics’ preferences, other attributes had limited or context-dependent effects on commercial success. This finding is particularly relevant to our project, as it suggests that not all musical features contribute equally to popularity outcomes, and that the feature importance may vary with the success metric used.\n",
    "\n",
    "Works like Georgieva et al. <sup><a href=\"#ref3\">3</a></sup>  similarly explore the predictive power of audio features for song popularity. They also framed hit prediction as a classification problem, showing that audio features extracted from songs, such as rhythm and harmony, can help predict whether songs are hits or non-hits in historical chart data. Their work further highlights the difficulty of consistently defining “success” across time periods and datasets, underscoring the importance of carefully selecting and interpreting popularity metrics.\n",
    "\n",
    "Together, these studies suggest that while audio features do contain meaningful information about popularity, their predictive strength is uneven and highly dependent on modeling choices and outcome definitions. Building on this prior work, our project aims to quantify the extent to which Spotify audio features predict popularity and identify which features are the strongest predictors.\n",
    "\n",
    "\n",
    "1. Araujo, Carlos, et al. Predicting Music Popularity on Streaming Platforms,<a href=\"https://www.researchgate.net/publication/341420234_Predicting_Music_Popularity_on_Streaming_Platforms\"> www.researchgate.net/publication/341420234_Predicting_Music_Popularity_on_Streaming_Platforms. </a>  \n",
    "2. Ceulemans, Cedric, and Lionel Detry. Does Music Matter in “Pop” Music? The Impact of Musical ...,<a href=\"https://www.cedricceulemans.net/uploads/2/0/4/2/20423775/does_music_matter_in_%E2%80%9Cpop%E2%80%9D_music.pdf\"> www.cedricceulemans.net/uploads/2/0/4/2/20423775/does_music_matter_in_%E2%80%9Cpop%E2%80%9D_music.pdf. </a>  \n",
    "3. Georgieva, Elena, et al. HIT PREDICT: Predicting Hit Songs Using Spotify Data,<a href=\"https://ccrma.stanford.edu/~egeorgie/documents/HitPredict_Final.pdf\"> ccrma.stanford.edu/~egeorgie/documents/HitPredict_Final.pdf. </a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that songs with higher danceability, energy, and loudness will have higher relative within genre popularity percentages, and that songs with higher instrumentalness and acousticness will tend to have lower relative within genre popularity. We expect these patterns because high energy songs are often promoted in mainstream and playlist-driven listening environments on Spotify, whereas more acoustic/instrumental tracks may appeal to narrower, more niche audiences. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ideal dataset should have variables containing features of the song that we want to analyze, such as danceability and energy, as well as a popularity score for the song. The dataset should also contain the genre so it can be properly filtered. We should aim for 10,000 observations, as this provides enough data to reliably calculate statistics for several different genres without being skewed by outliers. The data should be collected directly from Spotify and should be stored in a tidy data format such as a CSV that can be easily read in Python. \n",
    "Potential Sources: \n",
    "https://developer.spotify.com/documentation/web-api \n",
    "The data is on Spotify’s servers and needs a registered application in order to access the data. The important variables here are popularity and audio features such as danceability, energy, and valence. This dataset also has a release date variable that allows us to filter based on year which may be helpful. \n",
    "https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset/data \n",
    "The data is located at this Kaggle URL and can be downloaded immediately as a CSV file. No special permissions are required. The important variables are popularity, and audio features such as danceability, energy, and valence. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - X **A.1 Informed consent**  \n",
    "We do not collect data from human subjects, the data we collect comes from publicly available Spotify track level metadata and audio features, not from individual users or surveys.\n",
    " - X **A.2 Collection bias**  \n",
    "Our dataset only reflects Spotify’s platform, and Spotify’s recommendation algorithms and promotional systems influence which songs are visible to people who use their service. This could bias our sample, and means that are findings describe Spotify popularity rather than universal music popularity.\n",
    " - X **A.3 Limit PII exposure**  \n",
    "We do not collect or use personally identifiable information, instead, we analyze track level attributes. This minimizes privacy risks for Spotify user data. \n",
    " - X **A.4 Downstream bias mitigation**  \n",
    "Spotify does not provide protected demographic attributes like race or gender, so we cannot test for downstream bias across these groups. We acknowledge this limitation and avoid making demographic claims.\n",
    "### B. Data Storage\n",
    " - X **B.1 Data security**\n",
    " - X **B.2 Right to be forgotten**\n",
    " - X **B.3 Data retention plan**\n",
    "### C. Analysis\n",
    " - X **C.1 Missing perspectives**  \n",
    "Our analysis may miss perspectives from artists, smaller creators, or listeners outside Spotify, which is extremely important to address. We treat our findings as platform specific, with an emphasis of being exploratory and not making claims on what music should be developed. \n",
    " - X **C.2 Dataset bias**  \n",
    "Popularity may reflect marketing, current events, user playlist placement, or social trends rather than musical quality. We avoid interpreting popularity as artistic value, and make sure to frame results as platform insights and associations. \n",
    " - X **C.3 Honest representation**  \n",
    "In our insights and analysis, we will avoid overstating any correlations/patterns observed. We will not imply causation, and be sure to present results as associations.\n",
    " - X **C.4 Privacy in analysis**\n",
    " - X **C.5 Auditability**\n",
    "### D. Modeling\n",
    " - X **D.1 Proxy discrimination**  \n",
    "Our models use musical features rather than demographic data, but genre or language could indirectly heavily relate and influence to cultural groups. So we will avoid making demographic claims on our conclusions. \n",
    " - X **D.2 Fairness across groups**\n",
    " - X **D.3 Metric selection**  \n",
    "Spotify popularity reflects exposure and trends just as much as it reflects the quality of music streamed. We clearly communicate that it is not a measure of artistic value.\n",
    " - X **D.4 Explainability**\n",
    " - X **D.5 Communicate limitations**  \n",
    "We clearly state that our findings are Spotify platform specific and should be observed as associations. \n",
    "### E. Deployment\n",
    " - X **E.1 Monitoring and evaluation**\n",
    " - X **E.2 Redress**\n",
    " - X **E.3 Roll back**\n",
    " - X **E.4 Unintended use**  \n",
    "Models like ours could be used to encourage music creation that pertains to the traits that we prove are popular, generalizing art. We emphasize that our project explores patterns within the Spotify app, rather than prescribing how music should be made."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members: Roxana Behjat, David Li, Austin Flippo, Ryan Namdar, Farzad Kashani\n",
    "\n",
    "* We all agree for our team members to respond in our iMessage group chat in a timely manner, and that we will give honest and timely updates in case of emergencies. We agree to meet at least once a week, aiming for twice, in order to discuss our project, responsibilities, and to work together. \n",
    "\n",
    "* We aim to have consensus style decision making, where if we come to an impasse we will speak to each other and try to find the root of the issue and move forward as a group.\n",
    "\n",
    "* We agree to divide tasks evenly and to work through GitHub, where certain people might be working on more specific types of tasks, everyone will carry equal amount of weight in terms of work. We also agree to split work across divisions evenly, no one will only be doing coding, writing, etc.\n",
    "\n",
    "* We also all agree to be honest with each other, especially in times of conflict or miscommunication."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions: REPLACE the contents of this cell with your work\n",
    "\n",
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/28  |  4 PM | Review COGS 108 proposal requirements and rubric; brainstorm research queston & measurable variables  | Determine best form of communication fir group is iMessage groupchat; Finalize research question direction and project idea; Assign proposal section | \n",
    "| 2/4  |  2 PM |  Research question, hypothesis and background/prior work, initial Ethics checklist, candidate dataset list and variables | Group edit and finalize proposal with clarity and full scope; Determine dataset plan and analysis approach; finalize ethics writeup and submit proposal | \n",
    "| 2/18  | 3 PM  | Acquire dataset(s); create data dictonary with features and target; complete intial data cleaning with plan and code.  | Discuss Wrangling and review wrangling deicisons (missing values/outliers/duplicates); confirm feature set and target definition; plan EDA figures; finalize and submit Data Checkpoint. |\n",
    "| 3/4  | 6 PM  | Produce EDA outputs (distributions, correlations, popularity vs key features, any transforms); save key plots to results folder | Review and interpret EDA findings; discuss and refine analysis plan; choose our modeling approach and evaluation metrics; finalize and submit EDA checkpoint |\n",
    "| 3/11  | 2 PM  | Implement baseline models + grasp idea of first \"complete\" model(s); train and test split + CV; initial feature importance and coefficients; draft methods outline for final report | Compare models and metrics; evaluate to determine error/diagnostic analysis; decide next iterations of feature and tuning; Outline final project sections |\n",
    "| 3/17  | 12 PM  | Finalize analysis and checks; finalize tables/figures; draft reflections on results, disucssion, limitations and ethics; draft Final Project final submission end-to-end| Full-project review pass with clarity, visuals, claims vs evidence; reproducibility check to minimize any missed errors; finalize submission checklist |\n",
    "| 3/18  | Before 11:59 PM  | Final proofread; ensure all notebooks and modules run clean with no hidden errors; push final versions to github; complete any surveys | Turn in Final Project & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COGS108_FA25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
