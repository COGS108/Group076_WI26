{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with your team list and their contributions. Note that this will change over the course of the checkpoints\n",
    "\n",
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "Example team list and credits:\n",
    "- Alice Anderson: Conceptualization, Data curation, Methodology, Writing - original draft\n",
    "- Bob Barker:  Analysis, Software, Visualization\n",
    "- Charlie Chang: Project administration, Software, Writing - review & editing\n",
    "- Dani Delgado: Analysis, Background research, Visualization, Writing - original draft"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Spotify songs released between 2022–2026, which audio features (such as danceability, energy, valence, tempo, loudness, acousticness, and speechiness) are most strongly associated with a song’s relative popularity within its genre? Popularity will be measured using Spotify’s track popularity score compared within genres as a percentage, and we will also include control variables such as artist popularity and release year. We will use regression and analysis to find and understand these associations, which allows us to identify which musical features are most predictive of high relative popularity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our group began our work with the premise that what makes a hit song has become increasingly quantifiable in the era of big data and streaming platforms such as Spotify. Research into what makes a song popular, or at least what increases its likelihood of becoming a hit, has expanded rapidly in recent years. With the proliferation of music datasets and streaming platforms such as Spotify and Apple Music, researchers have sought to determine whether measurable audio features and musical characteristics are associated with commercial success, listener engagement, and critical reception. We focus on Spotify because it provides both a standardized set of audio features (danceability, energy, and valence) and a track-level popularity score on a 0-100 scale, calculated algorithmically and primarily driven by total plays and their recency.\n",
    "\n",
    "One research project by Araujo et al. <sup><a href=\"#ref1\">1</a></sup> used Spotify charts and audio features to model song popularity and predict whether a track would appear in Spotify’s Top 50 Global rankings in the future. They framed the task as a classification problem. They found that machine-learning models achieved strong predictive performance, with AUC (Area Under the Curve) values exceeding 0.80 when forecasting popularity up to two months in advance. Interestingly, they found that adding acoustic features to chart-based predictions yielded only minimal performance gains, suggesting that audio characteristics alone may have limited predictive power. This finding highlights a significant limitation and motivates our focus on identifying which specific Spotify audio features meaningfully contribute to popularity prediction rather than assuming all features are equally informative.\n",
    "\n",
    "Another related study by Ceulemans and Detry <sup><a href=\"#ref2\">2</a></sup>investigated whether musical characteristics influence commercial success and critics’ rankings preferences using a dataset of 514 songs from 2009 that appeared on multiple year-end charts. The authors constructed variables for tempo, duration, and other musical attributes. They then used regression models to assess their association with success metrics such as Billboard rank, chart longevity, and critics’ lists. Their results suggested that while some features were associated with chart survival and critics’ preferences, other attributes had limited or context-dependent effects on commercial success. This finding is particularly relevant to our project, as it suggests that not all musical features contribute equally to popularity outcomes, and that the feature importance may vary with the success metric used.\n",
    "\n",
    "Works like Georgieva et al. <sup><a href=\"#ref3\">3</a></sup>  similarly explore the predictive power of audio features for song popularity. They also framed hit prediction as a classification problem, showing that audio features extracted from songs, such as rhythm and harmony, can help predict whether songs are hits or non-hits in historical chart data. Their work further highlights the difficulty of consistently defining “success” across time periods and datasets, underscoring the importance of carefully selecting and interpreting popularity metrics.\n",
    "\n",
    "Together, these studies suggest that while audio features do contain meaningful information about popularity, their predictive strength is uneven and highly dependent on modeling choices and outcome definitions. Building on this prior work, our project aims to quantify the extent to which Spotify audio features predict popularity and identify which features are the strongest predictors.\n",
    "\n",
    "\n",
    "1. Araujo, Carlos, et al. Predicting Music Popularity on Streaming Platforms,<a href=\"https://www.researchgate.net/publication/341420234_Predicting_Music_Popularity_on_Streaming_Platforms\"> www.researchgate.net/publication/341420234_Predicting_Music_Popularity_on_Streaming_Platforms. </a>  \n",
    "2. Ceulemans, Cedric, and Lionel Detry. Does Music Matter in “Pop” Music? The Impact of Musical ...,<a href=\"https://www.cedricceulemans.net/uploads/2/0/4/2/20423775/does_music_matter_in_%E2%80%9Cpop%E2%80%9D_music.pdf\"> www.cedricceulemans.net/uploads/2/0/4/2/20423775/does_music_matter_in_%E2%80%9Cpop%E2%80%9D_music.pdf. </a>  \n",
    "3. Georgieva, Elena, et al. HIT PREDICT: Predicting Hit Songs Using Spotify Data,<a href=\"https://ccrma.stanford.edu/~egeorgie/documents/HitPredict_Final.pdf\"> ccrma.stanford.edu/~egeorgie/documents/HitPredict_Final.pdf. </a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that songs with higher danceability, energy, and loudness will have higher relative within genre popularity percentages, and that songs with higher instrumentalness and acousticness will tend to have lower relative within genre popularity. We expect these patterns because high energy songs are often promoted in mainstream and playlist-driven listening environments on Spotify, whereas more acoustic/instrumental tracks may appeal to narrower, more niche audiences. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - X **A.1 Informed consent**  \n",
    "We do not collect data from human subjects, the data we collect comes from publicly available Spotify track level metadata and audio features, not from individual users or surveys.\n",
    " - X **A.2 Collection bias**  \n",
    "Our dataset only reflects Spotify’s platform, and Spotify’s recommendation algorithms and promotional systems influence which songs are visible to people who use their service. This could bias our sample, and means that are findings describe Spotify popularity rather than universal music popularity.\n",
    " - X **A.3 Limit PII exposure**  \n",
    "We do not collect or use personally identifiable information, instead, we analyze track level attributes. This minimizes privacy risks for Spotify user data. \n",
    " - X **A.4 Downstream bias mitigation**  \n",
    "Spotify does not provide protected demographic attributes like race or gender, so we cannot test for downstream bias across these groups. We acknowledge this limitation and avoid making demographic claims.\n",
    "### B. Data Storage\n",
    " - X **B.1 Data security**\n",
    " - X **B.2 Right to be forgotten**\n",
    " - X **B.3 Data retention plan**\n",
    "### C. Analysis\n",
    " - X **C.1 Missing perspectives**  \n",
    "Our analysis may miss perspectives from artists, smaller creators, or listeners outside Spotify, which is extremely important to address. We treat our findings as platform specific, with an emphasis of being exploratory and not making claims on what music should be developed. \n",
    " - X **C.2 Dataset bias**  \n",
    "Popularity may reflect marketing, current events, user playlist placement, or social trends rather than musical quality. We avoid interpreting popularity as artistic value, and make sure to frame results as platform insights and associations. \n",
    " - X **C.3 Honest representation**  \n",
    "In our insights and analysis, we will avoid overstating any correlations/patterns observed. We will not imply causation, and be sure to present results as associations.\n",
    " - X **C.4 Privacy in analysis**\n",
    " - X **C.5 Auditability**\n",
    "### D. Modeling\n",
    " - X **D.1 Proxy discrimination**  \n",
    "Our models use musical features rather than demographic data, but genre or language could indirectly heavily relate and influence to cultural groups. So we will avoid making demographic claims on our conclusions. \n",
    " - X **D.2 Fairness across groups**\n",
    " - X **D.3 Metric selection**  \n",
    "Spotify popularity reflects exposure and trends just as much as it reflects the quality of music streamed. We clearly communicate that it is not a measure of artistic value.\n",
    " - X **D.4 Explainability**\n",
    " - X **D.5 Communicate limitations**  \n",
    "We clearly state that our findings are Spotify platform specific and should be observed as associations. \n",
    "### E. Deployment\n",
    " - X **E.1 Monitoring and evaluation**\n",
    " - X **E.2 Redress**\n",
    " - X **E.3 Roll back**\n",
    " - X **E.4 Unintended use**  \n",
    "Models like ours could be used to encourage music creation that pertains to the traits that we prove are popular, generalizing art. We emphasize that our project explores patterns within the Spotify app, rather than prescribing how music should be made."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members: Roxana Behjat, David Li, Austin Flippo, Ryan Namdar, Farzad Kashani\n",
    "\n",
    "* We all agree for our team members to respond in our iMessage group chat in a timely manner, and that we will give honest and timely updates in case of emergencies. We agree to meet at least once a week, aiming for twice, in order to discuss our project, responsibilities, and to work together. \n",
    "\n",
    "* We aim to have consensus style decision making, where if we come to an impasse we will speak to each other and try to find the root of the issue and move forward as a group.\n",
    "\n",
    "* We agree to divide tasks evenly and to work through GitHub, where certain people might be working on more specific types of tasks, everyone will carry equal amount of weight in terms of work. We also agree to split work across divisions evenly, no one will only be doing coding, writing, etc.\n",
    "\n",
    "* We also all agree to be honest with each other, especially in times of conflict or miscommunication."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/28  |  4 PM | Review COGS 108 proposal requirements and rubric; brainstorm research queston & measurable variables  | Determine best form of communication fir group is iMessage groupchat; Finalize research question direction and project idea; Assign proposal section | \n",
    "| 2/4  |  2 PM |  Research question, hypothesis and background/prior work, initial Ethics checklist, candidate dataset list and variables | Group edit and finalize proposal with clarity and full scope; Determine dataset plan and analysis approach; finalize ethics writeup and submit proposal | \n",
    "| 2/18  | 5:30 PM  | Acquire dataset(s); create data dictonary with features and target; complete intial data cleaning with plan and code.  | Discuss Wrangling and review wrangling deicisons (missing values/outliers/duplicates); confirm feature set and target definition; plan EDA figures; finalize and submit Data Checkpoint. |\n",
    "| 3/4  | 6 PM  | Produce EDA outputs (distributions, correlations, popularity vs key features, any transforms); save key plots to results folder | Review and interpret EDA findings; discuss and refine analysis plan; choose our modeling approach and evaluation metrics; finalize and submit EDA checkpoint |\n",
    "| 3/11  | 2 PM  | Implement baseline models + grasp idea of first \"complete\" model(s); train and test split + CV; initial feature importance and coefficients; draft methods outline for final report | Compare models and metrics; evaluate to determine error/diagnostic analysis; decide next iterations of feature and tuning; Outline final project sections |\n",
    "| 3/17  | 12 PM  | Finalize analysis and checks; finalize tables/figures; draft reflections on results, disucssion, limitations and ethics; draft Final Project final submission end-to-end| Full-project review pass with clarity, visuals, claims vs evidence; reproducibility check to minimize any missed errors; finalize submission checklist |\n",
    "| 3/18  | Before 11:59 PM  | Final proofread; ensure all notebooks and modules run clean with no hidden errors; push final versions to github; complete any surveys | Turn in Final Project & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
