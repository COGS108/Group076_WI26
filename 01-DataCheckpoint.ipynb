{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "- Austin Flippo: Research Question, Hypothesis, Ethics\n",
    "- David Li: Research Question, Hypothesis, Data Writing\n",
    "- Farzad Kashani: Rearch Question, Hypothesis, Background and Prior Work\n",
    "- Roxy Behjat: Research Question, Hypothesis, Background and Prior Work, Team Expectations\n",
    "- Ryan Namdar: Research Question, Hypothesis, Timeline, Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Spotify songs, which audio features (such as danceability, energy, valence, tempo, loudness, acousticness, and speechiness) are most strongly associated with a song’s relative popularity within its genre? Popularity will be measured using Spotify’s track popularity score compared within genres as a percentage, and we will also include control variables such as artist popularity. We will use regression and analysis to find and understand these associations, which allows us to identify which musical features are most predictive of high relative popularity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our group began our work with the premise that what makes a hit song has become increasingly quantifiable in the era of big data and streaming platforms such as Spotify. Research into what makes a song popular, or at least what increases its likelihood of becoming a hit, has expanded rapidly in recent years. With the proliferation of music datasets and streaming platforms such as Spotify and Apple Music, researchers have sought to determine whether measurable audio features and musical characteristics are associated with commercial success, listener engagement, and critical reception. We focus on Spotify because it provides both a standardized set of audio features (danceability, energy, and valence) and a track-level popularity score on a 0-100 scale, calculated algorithmically and primarily driven by total plays and their recency.\n",
    "\n",
    "One research project by Araujo et al. <sup><a href=\"#ref1\">1</a></sup> used Spotify charts and audio features to model song popularity and predict whether a track would appear in Spotify’s Top 50 Global rankings in the future. They framed the task as a classification problem. They found that machine-learning models achieved strong predictive performance, with AUC (Area Under the Curve) values exceeding 0.80 when forecasting popularity up to two months in advance. Interestingly, they found that adding acoustic features to chart-based predictions yielded only minimal performance gains, suggesting that audio characteristics alone may have limited predictive power. This finding highlights a significant limitation and motivates our focus on identifying which specific Spotify audio features meaningfully contribute to popularity prediction rather than assuming all features are equally informative.\n",
    "\n",
    "Another related study by Ceulemans and Detry <sup><a href=\"#ref2\">2</a></sup>investigated whether musical characteristics influence commercial success and critics’ rankings preferences using a dataset of 514 songs from 2009 that appeared on multiple year-end charts. The authors constructed variables for tempo, duration, and other musical attributes. They then used regression models to assess their association with success metrics such as Billboard rank, chart longevity, and critics’ lists. Their results suggested that while some features were associated with chart survival and critics’ preferences, other attributes had limited or context-dependent effects on commercial success. This finding is particularly relevant to our project, as it suggests that not all musical features contribute equally to popularity outcomes, and that the feature importance may vary with the success metric used.\n",
    "\n",
    "Works like Georgieva et al. <sup><a href=\"#ref3\">3</a></sup>  similarly explore the predictive power of audio features for song popularity. They also framed hit prediction as a classification problem, showing that audio features extracted from songs, such as rhythm and harmony, can help predict whether songs are hits or non-hits in historical chart data. Their work further highlights the difficulty of consistently defining “success” across time periods and datasets, underscoring the importance of carefully selecting and interpreting popularity metrics.\n",
    "\n",
    "Together, these studies suggest that while audio features do contain meaningful information about popularity, their predictive strength is uneven and highly dependent on modeling choices and outcome definitions. Building on this prior work, our project aims to quantify the extent to which Spotify audio features predict popularity and identify which features are the strongest predictors.\n",
    "\n",
    "\n",
    "1. Araujo, Carlos, et al. Predicting Music Popularity on Streaming Platforms,<a href=\"https://www.researchgate.net/publication/341420234_Predicting_Music_Popularity_on_Streaming_Platforms\"> www.researchgate.net/publication/341420234_Predicting_Music_Popularity_on_Streaming_Platforms. </a>  \n",
    "2. Ceulemans, Cedric, and Lionel Detry. Does Music Matter in “Pop” Music? The Impact of Musical ...,<a href=\"https://www.cedricceulemans.net/uploads/2/0/4/2/20423775/does_music_matter_in_%E2%80%9Cpop%E2%80%9D_music.pdf\"> www.cedricceulemans.net/uploads/2/0/4/2/20423775/does_music_matter_in_%E2%80%9Cpop%E2%80%9D_music.pdf. </a>  \n",
    "3. Georgieva, Elena, et al. HIT PREDICT: Predicting Hit Songs Using Spotify Data,<a href=\"https://ccrma.stanford.edu/~egeorgie/documents/HitPredict_Final.pdf\"> ccrma.stanford.edu/~egeorgie/documents/HitPredict_Final.pdf. </a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that songs with higher danceability, energy, and loudness will have higher relative within genre popularity percentages, and that songs with higher instrumentalness and acousticness will tend to have lower relative within genre popularity. We expect these patterns because high energy songs are often promoted in mainstream and playlist-driven listening environments on Spotify, whereas more acoustic/instrumental tracks may appeal to narrower, more niche audiences. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "- **Dataset #1: Spotify Tracks Dataset (Kaggle)**\n",
    "  - **Dataset Name:** Spotify Tracks Dataset by maharshipandya\n",
    "  - **Link to the dataset:** https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset/data\n",
    "  - **Number of observations:** ~9,000 tracks (1,000 per genre × 9 genres: hip-hop, country, pop, jazz, EDM, R&B, soul, rock, dance)\n",
    "  - **Number of variables:** 20 columns (4 categorical/string, 16 numeric)\n",
    "  - **Description of the variables most relevant to this project:**\n",
    "    - `popularity` (integer, 0–100): Spotify's algorithmic popularity score based on total play count and recency of streams. Higher values indicate more popular tracks. This is our primary outcome variable.\n",
    "    - `danceability` (float, 0.0–1.0): How suitable a track is for dancing based on tempo, rhythm stability, beat strength, and overall regularity. 1.0 = most danceable.\n",
    "    - `energy` (float, 0.0–1.0): Perceptual measure of intensity and activity. Energetic tracks feel fast, loud, and noisy. 1.0 = most energetic.\n",
    "    - `valence` (float, 0.0–1.0): Musical positiveness conveyed by a track. High valence = happy/cheerful, low valence = sad/angry.\n",
    "    - `tempo` (float, BPM): Estimated tempo in beats per minute.\n",
    "    - `loudness` (float, dB): Overall loudness in decibels, typically ranging from -60 to 0 dB.\n",
    "    - `acousticness` (float, 0.0–1.0): Confidence measure of whether the track is acoustic. 1.0 = high confidence acoustic.\n",
    "    - `speechiness` (float, 0.0–1.0): Detects presence of spoken words. Values above 0.66 indicate tracks that are probably entirely spoken word; below 0.33 are most likely music.\n",
    "    - `instrumentalness` (float, 0.0–1.0): Predicts whether a track contains no vocals. Values closer to 1.0 represent greater likelihood of no vocal content.\n",
    "    - `track_genre` (string): Genre classification for each track. We retain 9 genres: hip-hop, country, pop, jazz, EDM, R&B, soul, rock, and dance.\n",
    "    - `track_id` (string): Spotify's unique identifier for each track.\n",
    "  - **Shortcomings of this dataset:**\n",
    "    - The `popularity` score is a point-in-time snapshot and does not reflect current popularity.\n",
    "    - The same song may appear multiple times if released on both a single and an album, with potentially different popularity scores per entry.\n",
    "    - Genre is assigned at the track level in this dataset, not at the artist level, which may not always reflect the artist's primary genre.\n",
    "    - The dataset does not include a release date column, so we cannot filter by release year.\n",
    "    - The dataset was collected via the Spotify Web API before the audio features endpoint was deprecated (November 2024), so audio feature values reflect Spotify's internal algorithms at the time of collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules')\n",
    "\n",
    "import get_data\n",
    "\n",
    "# Kaggle Spotify Tracks Dataset (maharshipandya) hosted on HuggingFace\n",
    "datafiles = [\n",
    "    {\n",
    "        'url': 'https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset/resolve/main/dataset.csv',\n",
    "        'filename': 'spotify_tracks.csv'\n",
    "    }\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles, destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify Tracks Dataset (Kaggle)\n",
    "\n",
    "This dataset was originally collected from the Spotify Web API by Kaggle user maharshipandya and contains approximately 114,000 tracks spanning 114 genres. For this analysis we filter to 9 genres — hip-hop, country, pop, jazz, EDM, R&B, soul, rock, and dance — yielding ~9,000 tracks (1,000 per genre). Each row represents a single track, and the columns include Spotify's unique track ID, artist names, album name, track name, and a suite of audio features computed by Spotify's internal algorithms.\n",
    "\n",
    "**Key metrics and their meaning:**\n",
    "\n",
    "- **Popularity** (integer, 0–100): An algorithmic score primarily driven by the total number of plays a track has received and how recent those plays are. A score of 0 means the track has very few recent plays; 100 indicates an extremely high volume of recent streams. This is not a cumulative all-time count — it decays over time, so older songs with fewer recent plays will score lower even if they were historically popular.\n",
    "- **Danceability** (float, 0.0–1.0): Measures how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "- **Energy** (float, 0.0–1.0): A perceptual measure of intensity and activity. Energetic tracks typically feel fast, loud, and noisy (e.g., death metal scores high, a Bach prelude scores low).\n",
    "- **Valence** (float, 0.0–1.0): Describes the musical positiveness of a track. Tracks with high valence sound more positive (happy, cheerful, euphoric), while tracks with low valence sound more negative (sad, depressed, angry).\n",
    "- **Tempo** (float, BPM): The estimated tempo in beats per minute. Typical pop songs range from about 100–130 BPM, though the dataset spans a much wider range.\n",
    "- **Loudness** (float, decibels): The overall loudness of a track in dB. Values typically range from -60 dB (very quiet) to 0 dB (very loud). Most commercial music falls between -10 and -4 dB.\n",
    "- **Acousticness** (float, 0.0–1.0): A confidence measure of whether the track is acoustic. A value near 1.0 means high confidence that the track is acoustic.\n",
    "- **Speechiness** (float, 0.0–1.0): Detects the presence of spoken words. Tracks above 0.66 are probably entirely spoken word (podcasts, poetry), values between 0.33 and 0.66 may contain both music and speech (e.g., rap), and values below 0.33 most likely represent music without speech.\n",
    "- **Instrumentalness** (float, 0.0–1.0): Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental. Rap or spoken word tracks score close to 0.0. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "- **Track Genre** (string): The genre label assigned to each track. We retain 9 genres: hip-hop, country, pop, jazz, EDM, R&B, soul, rock, and dance.\n",
    "\n",
    "**Concerns with this dataset:**\n",
    "\n",
    "This dataset was collected at a single point in time, so the popularity scores represent a snapshot rather than current values. Spotify's popularity algorithm is recency-weighted, meaning these scores may not reflect a track's long-term success. Additionally, the same track can appear multiple times in the dataset if it was released on both a single and a full album, potentially with different popularity scores for each version. The dataset does not include a release date column, so no release-year filtering is applied. Finally, the audio features were computed by Spotify's proprietary algorithms, and the exact methodology is not fully disclosed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_raw = pd.read_csv('data/00-raw/spotify_tracks.csv')\n",
    "\n",
    "if 'Unnamed: 0' in df_raw.columns:\n",
    "    df_raw = df_raw.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "print(f\"Full dataset shape: {df_raw.shape}\")\n",
    "print()\n",
    "\n",
    "GENRES = ['hip-hop', 'country', 'pop', 'jazz', 'edm', 'r-n-b', 'soul', 'rock', 'dance']\n",
    "df_raw = df_raw[df_raw['track_genre'].isin(GENRES)].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"Filtered dataset shape (9 genres): {df_raw.shape}\")\n",
    "print(f\"  Rows (observations): {df_raw.shape[0]}\")\n",
    "print(f\"  Columns (variables): {df_raw.shape[1]}\")\n",
    "print()\n",
    "print(\"Rows per genre:\")\n",
    "print(df_raw['track_genre'].value_counts().sort_index())\n",
    "print()\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column names and dtypes:\")\n",
    "print(df_raw.dtypes)\n",
    "print()\n",
    "print(f\"Number of unique track IDs: {df_raw['track_id'].nunique()}\")\n",
    "print(f\"Number of rows: {len(df_raw)}\")\n",
    "print()\n",
    "\n",
    "n_dupes = df_raw.duplicated(subset='track_id').sum()\n",
    "print(f\"Duplicate track_id entries: {n_dupes}\")\n",
    "print(\"  (Same track can appear multiple times if released on single + album)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('data/01-interim', exist_ok=True)\n",
    "df_raw.to_csv('data/01-interim/spotify_tracks_9genres.csv', index=False)\n",
    "print(f\"Interim data saved to data/01-interim/spotify_tracks_9genres.csv\")\n",
    "print(f\"Shape: {df_raw.shape}\")\n",
    "\n",
    "df = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df)) * 100\n",
    "missing_summary = pd.DataFrame({\n",
    "    'missing_count': missing_counts,\n",
    "    'missing_pct': missing_pct\n",
    "}).sort_values('missing_count', ascending=False)\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_summary[missing_summary['missing_count'] > 0])\n",
    "print()\n",
    "if missing_summary['missing_count'].sum() == 0:\n",
    "    print(\"No missing values found in any column.\")\n",
    "else:\n",
    "    print(f\"Total missing values: {missing_summary['missing_count'].sum()}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "sns.heatmap(df.isnull().T, cbar=True, yticklabels=True, cmap='viridis', ax=ax)\n",
    "ax.set_title('Missing Data Heatmap (yellow = missing)')\n",
    "ax.set_xlabel('Row index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "rows_with_missing = df.isnull().any(axis=1).sum()\n",
    "print(f\"\\nRows with at least one missing value: {rows_with_missing} / {len(df)} \"\n",
    "      f\"({rows_with_missing / len(df):.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['popularity', 'duration_ms', 'danceability', 'energy', 'loudness',\n",
    "                'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "                'valence', 'tempo']\n",
    "\n",
    "outlier_summary = []\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    n_outliers = ((df[col] < lower) | (df[col] > upper)).sum()\n",
    "    outlier_summary.append({\n",
    "        'column': col,\n",
    "        'Q1': round(Q1, 4),\n",
    "        'Q3': round(Q3, 4),\n",
    "        'IQR': round(IQR, 4),\n",
    "        'lower_bound': round(lower, 4),\n",
    "        'upper_bound': round(upper, 4),\n",
    "        'n_outliers': n_outliers,\n",
    "        'pct_outliers': round(n_outliers / len(df) * 100, 2)\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(\"Outlier summary (IQR method, 1.5x IQR):\")\n",
    "print(outlier_df.to_string(index=False))\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "plot_cols = ['popularity', 'danceability', 'energy', 'loudness',\n",
    "             'speechiness', 'acousticness', 'instrumentalness', 'valence']\n",
    "for ax, col in zip(axes.flatten(), plot_cols):\n",
    "    ax.boxplot(df[col].dropna(), vert=True)\n",
    "    ax.set_title(col)\n",
    "    ax.set_ylabel(col)\n",
    "plt.suptitle('Boxplots of Key Audio Features (outliers shown as dots)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "short_tracks = df[df['duration_ms'] < 30000]\n",
    "long_tracks = df[df['duration_ms'] > 600000]\n",
    "print(f\"\\nSuspicious duration entries:\")\n",
    "print(f\"  Tracks shorter than 30 seconds: {len(short_tracks)}\")\n",
    "print(f\"  Tracks longer than 10 minutes: {len(long_tracks)}\")\n",
    "\n",
    "zero_tempo = df[df['tempo'] == 0]\n",
    "print(f\"  Tracks with tempo = 0 BPM: {len(zero_tempo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape before cleaning: {df.shape}\")\n",
    "print()\n",
    "\n",
    "n_exact_dupes = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Dropped {n_exact_dupes} exact duplicate rows.\")\n",
    "\n",
    "n_before_dedup = len(df)\n",
    "df = df.sort_values('popularity', ascending=False).drop_duplicates(subset='track_id', keep='first')\n",
    "n_after_dedup = len(df)\n",
    "print(f\"Dropped {n_before_dedup - n_after_dedup} duplicate track_id entries \"\n",
    "      f\"(kept highest popularity per track).\")\n",
    "\n",
    "key_cols = ['popularity', 'danceability', 'energy', 'loudness', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "            'track_genre']\n",
    "n_before_drop = len(df)\n",
    "df = df.dropna(subset=key_cols, how='any')\n",
    "print(f\"Dropped {n_before_drop - len(df)} rows with missing values in key columns.\")\n",
    "\n",
    "n_before_short = len(df)\n",
    "df = df[df['duration_ms'] >= 30000]\n",
    "print(f\"Dropped {n_before_short - len(df)} tracks shorter than 30 seconds.\")\n",
    "\n",
    "n_before_tempo = len(df)\n",
    "df = df[df['tempo'] > 0]\n",
    "print(f\"Dropped {n_before_tempo - len(df)} tracks with tempo = 0 BPM.\")\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print(f\"\\nFinal cleaned dataset shape: {df.shape}\")\n",
    "print(f\"  Rows: {df.shape[0]}\")\n",
    "print(f\"  Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data/02-processed', exist_ok=True)\n",
    "df.to_csv('data/02-processed/spotify_tracks_clean.csv', index=False)\n",
    "print(\"Cleaned data saved to data/02-processed/spotify_tracks_clean.csv\")\n",
    "print()\n",
    "\n",
    "print(\"=== Post-cleaning verification ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Missing values in key columns: {df[key_cols].isnull().sum().sum()}\")\n",
    "print(f\"Duplicate track_ids: {df.duplicated(subset='track_id').sum()}\")\n",
    "print(f\"Tracks with duration < 30s: {(df['duration_ms'] < 30000).sum()}\")\n",
    "print(f\"Tracks with tempo = 0: {(df['tempo'] == 0).sum()}\")\n",
    "print()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "sns.heatmap(df.isnull().T, cbar=True, yticklabels=True, cmap='viridis', ax=ax)\n",
    "ax.set_title('Missing Data Heatmap AFTER Cleaning (yellow = missing)')\n",
    "ax.set_xlabel('Row index')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData is clean and ready for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols = ['popularity', 'danceability', 'energy', 'valence', 'tempo',\n",
    "                'loudness', 'acousticness', 'speechiness', 'instrumentalness',\n",
    "                'liveness', 'duration_ms']\n",
    "\n",
    "print(\"Summary statistics for key audio features:\")\n",
    "print(df[summary_cols].describe().round(4).to_string())\n",
    "print()\n",
    "\n",
    "print(f\"Number of unique genres: {df['track_genre'].nunique()}\")\n",
    "print(f\"\\nTrack count per genre:\")\n",
    "print(df['track_genre'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Additional Datasets\n",
    "\n",
    "This project uses a single comprehensive dataset (the Kaggle Spotify Tracks Dataset) filtered to 9 genres: hip-hop, country, pop, jazz, EDM, R&B, soul, rock, and dance. This subset of ~9,000 tracks contains all the variables needed for our analysis — audio features, popularity scores, and genre labels. The Kaggle dataset does not include release dates, and the Spotify audio features API was deprecated in November 2024, so no API enrichment is applied. We may incorporate additional datasets in future checkpoints if needed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "Instructions: Keep the contents of this cell. For each item on the checklist\n",
    "-  put an X there if you've considered the item\n",
    "-  IF THE ITEM IS RELEVANT place a short paragraph after the checklist item discussing the issue.\n",
    "  \n",
    "Items on this checklist are meant to provoke discussion among good-faith actors who take their ethical responsibilities seriously. Your teams will document these discussions and decisions for posterity using this section.  You don't have to solve these problems, you just have to acknowledge any potential harm no matter how unlikely.\n",
    "\n",
    "Here is a [list of real world examples](https://deon.drivendata.org/examples/) for each item in the checklist that can refer to.\n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - X **A.1 Informed consent**  \n",
    "We do not collect data from human subjects, the data we collect comes from publicly available Spotify track level metadata and audio features, not from individual users or surveys.\n",
    " - X **A.2 Collection bias**  \n",
    "Our dataset only reflects Spotify’s platform, and Spotify’s recommendation algorithms and promotional systems influence which songs are visible to people who use their service. This could bias our sample, and means that are findings describe Spotify popularity rather than universal music popularity.\n",
    " - X **A.3 Limit PII exposure**  \n",
    "We do not collect or use personally identifiable information, instead, we analyze track level attributes. This minimizes privacy risks for Spotify user data. \n",
    " - X **A.4 Downstream bias mitigation**  \n",
    "Spotify does not provide protected demographic attributes like race or gender, so we cannot test for downstream bias across these groups. We acknowledge this limitation and avoid making demographic claims.\n",
    "### B. Data Storage\n",
    " - X **B.1 Data security**\n",
    " - X **B.2 Right to be forgotten**\n",
    " - X **B.3 Data retention plan**\n",
    "### C. Analysis\n",
    " - X **C.1 Missing perspectives**  \n",
    "Our analysis may miss perspectives from artists, smaller creators, or listeners outside Spotify, which is extremely important to address. We treat our findings as platform specific, with an emphasis of being exploratory and not making claims on what music should be developed. \n",
    " - X **C.2 Dataset bias**  \n",
    "Popularity may reflect marketing, current events, user playlist placement, or social trends rather than musical quality. We avoid interpreting popularity as artistic value, and make sure to frame results as platform insights and associations. \n",
    " - X **C.3 Honest representation**  \n",
    "In our insights and analysis, we will avoid overstating any correlations/patterns observed. We will not imply causation, and be sure to present results as associations.\n",
    " - X **C.4 Privacy in analysis**\n",
    " - X **C.5 Auditability**\n",
    "### D. Modeling\n",
    " - X **D.1 Proxy discrimination**  \n",
    "Our models use musical features rather than demographic data, but genre or language could indirectly heavily relate and influence to cultural groups. So we will avoid making demographic claims on our conclusions. \n",
    " - X **D.2 Fairness across groups**\n",
    " - X **D.3 Metric selection**  \n",
    "Spotify popularity reflects exposure and trends just as much as it reflects the quality of music streamed. We clearly communicate that it is not a measure of artistic value.\n",
    " - X **D.4 Explainability**\n",
    " - X **D.5 Communicate limitations**  \n",
    "We clearly state that our findings are Spotify platform specific and should be observed as associations. \n",
    "### E. Deployment\n",
    " - X **E.1 Monitoring and evaluation**\n",
    " - X **E.2 Redress**\n",
    " - X **E.3 Roll back**\n",
    " - X **E.4 Unintended use**  \n",
    "Models like ours could be used to encourage music creation that pertains to the traits that we prove are popular, generalizing art. We emphasize that our project explores patterns within the Spotify app, rather than prescribing how music should be made."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members: Roxana Behjat, David Li, Austin Flippo, Ryan Namdar, Farzad Kashani\n",
    "\n",
    "* We all agree for our team members to respond in our iMessage group chat in a timely manner, and that we will give honest and timely updates in case of emergencies. We agree to meet at least once a week, aiming for twice, in order to discuss our project, responsibilities, and to work together. \n",
    "\n",
    "* We aim to have consensus style decision making, where if we come to an impasse we will speak to each other and try to find the root of the issue and move forward as a group.\n",
    "\n",
    "* We agree to divide tasks evenly and to work through GitHub, where certain people might be working on more specific types of tasks, everyone will carry equal amount of weight in terms of work. We also agree to split work across divisions evenly, no one will only be doing coding, writing, etc.\n",
    "\n",
    "* We also all agree to be honest with each other, especially in times of conflict or miscommunication."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/28  |  4 PM | Review COGS 108 proposal requirements and rubric; brainstorm research queston & measurable variables  | Determine best form of communication fir group is iMessage groupchat; Finalize research question direction and project idea; Assign proposal section | \n",
    "| 2/4  |  2 PM |  Research question, hypothesis and background/prior work, initial Ethics checklist, candidate dataset list and variables | Group edit and finalize proposal with clarity and full scope; Determine dataset plan and analysis approach; finalize ethics writeup and submit proposal | \n",
    "| 2/18  | 5:30 PM  | Acquire dataset(s); create data dictonary with features and target; complete intial data cleaning with plan and code.  | Discuss Wrangling and review wrangling deicisons (missing values/outliers/duplicates); confirm feature set and target definition; plan EDA figures; finalize and submit Data Checkpoint. |\n",
    "| 3/4  | 6 PM  | Produce EDA outputs (distributions, correlations, popularity vs key features, any transforms); save key plots to results folder | Review and interpret EDA findings; discuss and refine analysis plan; choose our modeling approach and evaluation metrics; finalize and submit EDA checkpoint |\n",
    "| 3/11  | 2 PM  | Implement baseline models + grasp idea of first \"complete\" model(s); train and test split + CV; initial feature importance and coefficients; draft methods outline for final report | Compare models and metrics; evaluate to determine error/diagnostic analysis; decide next iterations of feature and tuning; Outline final project sections |\n",
    "| 3/17  | 12 PM  | Finalize analysis and checks; finalize tables/figures; draft reflections on results, disucssion, limitations and ethics; draft Final Project final submission end-to-end| Full-project review pass with clarity, visuals, claims vs evidence; reproducibility check to minimize any missed errors; finalize submission checklist |\n",
    "| 3/18  | Before 11:59 PM  | Final proofread; ensure all notebooks and modules run clean with no hidden errors; push final versions to github; complete any surveys | Turn in Final Project & Group Project Surveys |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
